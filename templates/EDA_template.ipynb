{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ad1a49a-e27c-439b-ae65-791edc0b92bd",
   "metadata": {},
   "source": [
    "# EDA template"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b097382-4424-4fa3-a77d-ee9f5e1867d5",
   "metadata": {},
   "source": [
    "## Packages import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cbe9e93-c734-4f2c-a7d2-7abaaa2c9f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# extras if you want to concatenate nultiple files into a df\n",
    "import os \n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bb9f8de-3cde-4434-ba08-51ba9331e776",
   "metadata": {},
   "source": [
    "## Defining useful functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e71a1e7f-3811-461d-b3ac-7913f7a06aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def null_vals(dataframe):\n",
    "    '''function to show both number of nulls and the percentage of nulls in the whole column'''\n",
    "    null_vals = dataframe.isnull().sum()\n",
    "    total_cnt = len(dataframe)\n",
    "    null_vals = pd.DataFrame(null_vals,columns=['null'])\n",
    "    null_vals['percent'] = round((null_vals['null']/total_cnt)*100,3)\n",
    "    return null_vals.sort_values('percent', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb2b2c1-48d1-4459-8939-73893a72d862",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove price outliars in every year\n",
    "def drop_outliers(df, column):\n",
    "    \"\"\"Function that drops outliers for year to year\"\"\"\n",
    "    for x in df.age.unique(): #we loop through each unique year\n",
    "        for col in column: #We loop through the different columns\n",
    "\n",
    "            #Select the data between th 25th and 75th percentile\n",
    "            q75,q25 = np.percentile(df[df.age == x].loc[:,col],[75,25]) ########\n",
    "            intr_qr = q75-q25\n",
    "\n",
    "            # We extend the range of the upper and lower bound\n",
    "            upper = q75+(1.5*intr_qr)\n",
    "            lower = q25-(1.5*intr_qr) \n",
    "\n",
    "            df.loc[((df[col] < lower) | (df[col] > upper)) \n",
    "            & (df.age == x), col] = np.nan\n",
    "            \n",
    "    df = df.dropna(axis = 0, subset=column).reset_index(drop=True)\n",
    "    \n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8359c1bd-e0e7-4915-8c62-5695472005d2",
   "metadata": {},
   "source": [
    "## Data import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa21e51d-455b-4d25-a78a-adb40537c4e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the data\n",
    "df = pd.read_csv('*.csv')\n",
    "\n",
    "# If the size of the file is very big you can use this instead\n",
    "chunk = pd.read_csv('*.csv',chunksize=1000000)\n",
    "df = pd.concat(chunk) # concatenate chucks of file\n",
    "\n",
    "# if we want to make a dataframe from multiple files\n",
    "# Import all csv files in bulks\n",
    "\n",
    "filenames=[]\n",
    "dfs=[]\n",
    "directory_path = '.'\n",
    "\n",
    "for path in Path(directory_path).rglob('*.csv'):\n",
    "    filenames.append(str(path.absolute()))\n",
    "    dfs.append(pd.read_csv(str(path.absolute())))#,encoding='mbcs'))\n",
    "\n",
    "# Create the dataframe from the list dfs\n",
    "df=pd.concat(dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c330d0c-540b-4f5a-957b-17416dfc615f",
   "metadata": {},
   "source": [
    "## Data inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7efe5c06-a4df-478d-a5a9-701723f54134",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read first 5 lines\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f18539bb-dffe-4ae3-9c25-7be25e9c5e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read last five lines\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9222b7df-b889-4632-8f57-57c040632d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of rows and columns\n",
    "df.shape\n",
    "\n",
    "print(f'The dataframe has {df.shape[0]} rows and {df.shape[1]} columns.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cea1dfc-561d-4ba9-8d6f-fc3efd02cbd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data types of each column\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11bde367-a166-4b2b-95a4-fcb6af7b082f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking if nulls are present\n",
    "null_vals(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1592e720-8032-4366-a752-d97b5d7e1fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# count number of items in a particular column\n",
    "df['column'].value_counts(dropna = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a8a2480-78db-45e8-b95b-7d839060e433",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ba7188-a0b3-4eda-9b0b-1389278f6e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make column name lower case and remove spaces from the column names\n",
    "df.rename(columns=str.lower,inplace = True)\n",
    "df.columns = df.columns.str.replace(' ', '_', regex=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb130ad-9762-479a-8ce3-36541ee1d167",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filling NAs with 0s \n",
    "df['column'].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d47ef7f2-ebc0-40b9-b92b-7c90ee8bd202",
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace missing nulls with mean Age\n",
    "df['column'] = df.groupby('column')['Age'].transform(lambda x: x.fillna(x.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c1dd1c7-0b15-4d5d-92e8-69df5253f7e7",
   "metadata": {},
   "source": [
    "## Data Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d02f596-0ffb-4be6-929c-dd714ebf1b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b260542-38ed-4dc6-8f79-acb5ed2e6ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "945ec3c1-eb62-41ef-a60f-3295697caa44",
   "metadata": {},
   "source": [
    "## Datecting outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ffd58c9-7d0f-44ec-8233-573c35f38ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "424a410a-680f-4004-b19c-a31978c9af04",
   "metadata": {},
   "outputs": [],
   "source": [
    "df= drop_outliers(df, ['column1', 'column2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea7eb25-ca45-42cb-be03-580728244d84",
   "metadata": {},
   "source": [
    "## Data correlations and Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "054c8322-c0ae-4eaf-9c2e-8f4a2da9075a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlations between numerical features\n",
    "df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cdbcdfd-ae32-4522-8b9e-eaf09384312d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualising correlations as heatmap\n",
    "plt.figure(figsize = (10, 10))\n",
    "sns.heatmap(df.corr(), annot = True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d974e3-0760-4d5e-b416-855bf8df59b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualising correlations as scatter matrices\n",
    "pd.plotting.scatter_matrix(df, figsize=(20,20))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9df0a29e-2487-4631-b4e1-87b509f02464",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(df[['column1', 'column2']], height = 6)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
